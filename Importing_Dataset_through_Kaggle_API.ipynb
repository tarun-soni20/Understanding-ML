{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Dataset through Kaggle APIipynb"
      ],
      "metadata": {
        "id": "GyYjdsJvBTHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2j4Du_tAI44i"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omNQCDILBOP5",
        "outputId": "625c5b60-c335-4d45-ad18-d813948942af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "#installing the kaggle library\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uploading Kaggle .json file"
      ],
      "metadata": {
        "id": "1tP_4cFZCNQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#configuring the path of kaggle .json files\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "HjYVhr_PBc5W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly, let's break down what each line of this code does:\n",
        "\n",
        "1. `!mkdir -p ~/.kaggle`\n",
        "   - This line is using a shell command in a Jupyter Notebook (Google Colab uses Jupyter Notebooks) to create a directory named `.kaggle` in the user's home directory (`~`). The `-p` flag ensures that the command creates parent directories if they don't exist. The directory will be used to store Kaggle API-related files.\n",
        "\n",
        "2. `!cp kaggle.json ~/.kaggle/`\n",
        "   - This line uses the `cp` command to copy a file named `kaggle.json` to the `.kaggle` directory in the user's home directory. The `kaggle.json` file is expected to contain the Kaggle API token, which is necessary for interacting with Kaggle's APIs. It's likely that you need to manually upload this file to your Colab environment before running this line of code.\n",
        "\n",
        "3. `!chmod 600 ~/.kaggle/kaggle.json`\n",
        "   - This line uses the `chmod` command to change the permissions of the `kaggle.json` file. The numbers `600` represent the permissions in octal notation. In this context, `6` means read and write permission for the owner of the file (`kaggle.json`), and no permissions for any other users. This ensures that only the owner can read and write the file, which is important for security since the file contains sensitive information (Kaggle API credentials).\n",
        "\n",
        "In summary, this code snippet is preparing the environment to use the Kaggle API by creating a directory for storing the Kaggle API token (`kaggle.json`), copying the token file into that directory, and then setting the appropriate permissions to protect the sensitive API token information. Make sure to upload the `kaggle.json` file to your Colab environment before running this code, and ensure that the file contains the correct API credentials."
      ],
      "metadata": {
        "id": "kKEpdArbJeGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#API to fetch the dataset from kaggle\n",
        "!kaggle competitions download -c LANL-Earthquake-Prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIgxP3T-DM7M",
        "outputId": "6c61a2d9-df71-42f3-d964-e6ba4d949fb5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LANL-Earthquake-Prediction.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting the compressed Dataset\n",
        "from zipfile import ZipFile\n",
        "dataset = '/content/LANL-Earthquake-Prediction.zip'\n",
        "with ZipFile(dataset,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The Dataset is extracted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edSyZCLgEkLP",
        "outputId": "23dd4aff-46ce-4ccc-fc46-0796b6161cc6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Dataset is extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/train.csv')\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "CzT0Em7oIC35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tud5t5KlI_yO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}